from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os
import openai
import time
import traceback
import requests
import redis
import json
from datetime import datetime
import hashlib
import threading
import concurrent.futures

app = Flask(__name__)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
redis_url = os.getenv('REDIS_URL')
if not redis_url:
    raise ValueError("REDIS_URL is not set")
redis_db = redis.StrictRedis.from_url(redis_url, decode_responses=True,
                                     max_connections=10)  # é™åˆ¶é€£æ¥æ•¸

line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))

openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY is not set")

client = openai.OpenAI(api_key=openai_api_key, timeout=25.0)  # æ¸›å°‘timeout
ASSISTANT_ID = os.getenv('ASSISTANT_ID') 

# --- 2. æ ¹æ“šç¡¬é«”å„ªåŒ–è¨­å®š ---
MAX_THREAD_MESSAGES = 15          # é©ç•¶å¢åŠ å°è©±è¨˜æ†¶
MAX_MESSAGE_LENGTH = 2000         # é™åˆ¶å–®æ¢è¨Šæ¯é•·åº¦
MAX_CONCURRENT_REQUESTS = 4       # æ¸›å°‘ä½µç™¼æ•¸ï¼ˆ0.5 CPUï¼‰
MAX_WORKERS = 3                   # èƒŒæ™¯åŸ·è¡Œç·’æ•¸
REQUEST_TIMEOUT = 12              # è«‹æ±‚è¶…æ™‚æ™‚é–“
REDIS_MAX_PER_STUDENT = 80        # æ¯ç”Ÿæœ€å¤§è¨Šæ¯æ•¸

# --- 3. è³‡æºç›£æ§ ---
class ResourceMonitor:
    def __init__(self):
        self.request_count = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def increment(self):
        with self.lock:
            self.request_count += 1
    
    def get_stats(self):
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                "total_requests": self.request_count,
                "requests_per_minute": self.request_count / (uptime / 60) if uptime > 0 else 0,
                "uptime_hours": round(uptime / 3600, 2)
            }

monitor = ResourceMonitor()

# --- 4. å„ªåŒ–è³‡æ–™å„²å­˜ ---
def generate_anonymous_id(user_id):
    return hashlib.md5(user_id.encode()).hexdigest()[:10]  # æ›´çŸ­ID

def save_message_optimized(user_id, role, content):
    """ç¯€çœè¨˜æ†¶é«”çš„å„²å­˜æ–¹å¼"""
    try:
        student_id = generate_anonymous_id(user_id)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")  # æ›´ç·Šæ¹Šæ™‚é–“æ ¼å¼
        
        # å£“ç¸®å…§å®¹
        if len(content) > MAX_MESSAGE_LENGTH:
            keep = MAX_MESSAGE_LENGTH // 2
            content = content[:keep] + "..." + content[-keep//2:]
        
        # æœ€å°åŒ–è³‡æ–™çµæ§‹
        message_data = {
            "s": student_id,
            "r": role[0],  # 'u' æˆ– 'a'
            "c": content,
            "t": timestamp
        }
        
        # ä½¿ç”¨æ›´çŸ­çš„éµå
        key = f"h:{student_id}"
        redis_db.rpush(key, json.dumps(message_data, separators=(',', ':')))
        
        # åš´æ ¼æ§åˆ¶æ­·å²é•·åº¦
        if redis_db.llen(key) > REDIS_MAX_PER_STUDENT:
            redis_db.ltrim(key, -REDIS_MAX_PER_STUDENT, -1)
        
        return True
    except Exception as e:
        print(f"Save optimized error: {e}")
        return False

# --- 5. GPT_response å‡½æ•¸ï¼ˆè³‡æºæ„ŸçŸ¥ï¼‰---
def GPT_response(user_id, text):
    """è³‡æºæ„ŸçŸ¥çš„ AI å›æ‡‰å‡½æ•¸"""
    monitor.increment()
    
    try:
        # æª¢æŸ¥è³‡æºä½¿ç”¨ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        if monitor.get_stats()["requests_per_minute"] > 30:
            return "System is busy. Please wait a moment and try again."
        
        # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯
        save_message_optimized(user_id, "user", text[:1500])  # é€²ä¸€æ­¥é™åˆ¶è¼¸å…¥é•·åº¦
        
        # å–å¾—æˆ–å‰µå»º thread
        thread_id = redis_db.get(f"t:{user_id}")  # æ›´çŸ­çš„éµå
        
        # æ™ºèƒ½æ¸…ç† thread
        if thread_id:
            try:
                # å¿«é€Ÿæª¢æŸ¥è¨Šæ¯æ•¸é‡
                messages = client.beta.threads.messages.list(
                    thread_id=thread_id,
                    limit=MAX_THREAD_MESSAGES + 2,
                    timeout=2.0
                )
                
                # å¦‚æœè¶…éé™åˆ¶ï¼Œæ¸…ç†åˆ°ä¿ç•™8æ¢
                if len(messages.data) > MAX_THREAD_MESSAGES:
                    print(f"Cleaning thread ({len(messages.data)} -> 8)")
                    
                    # åªä¿ç•™æœ€è¿‘8æ¢
                    keep_messages = []
                    for msg in messages.data[-8:]:
                        if hasattr(msg, 'content') and msg.content:
                            content = msg.content[0].text.value
                            if len(content) > 800:
                                content = content[:800] + "..."
                            keep_messages.append({
                                "role": msg.role,
                                "content": content
                            })
                    
                    if keep_messages:
                        new_thread = client.beta.threads.create(
                            messages=keep_messages
                        )
                        thread_id = new_thread.id
                        redis_db.setex(f"t:{user_id}", 2400, thread_id)  # 40åˆ†é˜
                    else:
                        thread_id = None
                        
            except Exception as e:
                print(f"Thread cleanup error: {e}")
                thread_id = None
        
        # å‰µå»ºæ–° thread
        if not thread_id:
            thread = client.beta.threads.create(
                messages=[{"role": "user", "content": text[:1500]}]
            )
            thread_id = thread.id
            redis_db.setex(f"t:{user_id}", 2400, thread_id)
        
        # åŠ å…¥æ–°è¨Šæ¯
        else:
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=text[:1500],
                timeout=2.0
            )
        
        # åŸ·è¡ŒåŠ©ç†ï¼ˆè¼ƒçŸ­timeoutï¼‰
        run = client.beta.threads.runs.create(
            thread_id=thread_id, 
            assistant_id=ASSISTANT_ID,
            timeout=6.0
        )
        
        # ç­‰å¾…å®Œæˆï¼ˆæœ€å¤š10ç§’ï¼‰
        start = time.time()
        while run.status != "completed":
            if time.time() - start > REQUEST_TIMEOUT:
                return "Processing taking longer than usual. Please try a shorter question."
            
            if run.status in ["failed", "cancelled", "expired"]:
                error_msg = run.last_error.message[:100] if run.last_error else "Unknown"
                print(f"Run failed: {error_msg}")
                break
            
            time.sleep(0.6)  # æ¸›å°‘æª¢æŸ¥é »ç‡
            run = client.beta.threads.runs.retrieve(
                thread_id=thread_id, 
                run_id=run.id,
                timeout=2.0
            )
        
        # å–å¾—å›è¦†
        messages = client.beta.threads.messages.list(
            thread_id=thread_id,
            order="desc",
            limit=1,
            timeout=2.0
        )
        
        if not messages.data or not messages.data[0].content:
            return "No response generated."
            
        ai_reply = messages.data[0].content[0].text.value
        
        # å„²å­˜å›è¦†ï¼ˆé™åˆ¶é•·åº¦ï¼‰
        save_message_optimized(user_id, "assistant", ai_reply[:2000])
        
        # å®šæœŸæ¸…ç†è¨ˆæ•¸å™¨
        conv_key = f"c:{user_id}"
        conv_count = redis_db.incr(conv_key)
        redis_db.expire(conv_key, 1800)
        
        if conv_count >= 6:  # æ¯6æ¬¡å°è©±æ¸…ç†
            redis_db.delete(conv_key)
            redis_db.delete(f"t:{user_id}")
            print(f"Periodic cleanup for {user_id[:8]}")
        
        return ai_reply
        
    except openai.APITimeoutError:
        return "AI service timeout. Please try again."
        
    except Exception as e:
        print(f"GPT_response error: {e}")
        return "System error. Please try again."

# --- 6. LINE è™•ç†ï¼ˆä¿æŒä¸è®Šä½†å„ªåŒ–ï¼‰---
executor = concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS)

def send_loading(chat_id):
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/start'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id, "loadingSeconds": 9}
        requests.post(url, headers=headers, json=data, timeout=2)
    except:
        pass

def stop_loading(chat_id):
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/stop'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id}
        requests.post(url, headers=headers, json=data, timeout=2)
    except:
        pass

def process_background(user_id, text, reply_token):
    try:
        send_loading(user_id)
        answer = GPT_response(user_id, text)
        stop_loading(user_id)
        
        if len(answer) > 2500:
            answer = answer[:2500] + "\n\n[Trimmed]"
        
        line_bot_api.reply_message(
            reply_token, 
            TextSendMessage(text=answer)
        )
        
    except Exception as e:
        print(f"Background error: {e}")
        try:
            stop_loading(user_id)
        except:
            pass

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
        return 'OK', 200
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        print(f"Callback error: {e}")
        return 'OK', 200

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg_id = event.message.id
    user_msg = event.message.text
    user_id = event.source.user_id
    reply_token = event.reply_token

    # é˜²é‡è¤‡è™•ç†
    if redis_db.get(f"p:{msg_id}"):
        return 
    redis_db.setex(f"p:{msg_id}", 20, "1")

    # ç¾¤çµ„éæ¿¾
    if event.source.type == 'group':
        if 'bot' not in user_msg.lower() and '@AI' not in user_msg:
            redis_db.delete(f"p:{msg_id}")
            return
    
    # æäº¤èƒŒæ™¯è™•ç†
    executor.submit(process_background, user_id, user_msg, reply_token)

# --- 7. ç®¡ç†ç«¯é» ---
@app.route("/health", methods=['GET'])
def health_check():
    try:
        redis_db.ping()
        stats = monitor.get_stats()
        return jsonify({
            "status": "healthy",
            "resources": stats,
            "config": {
                "max_concurrent": MAX_CONCURRENT_REQUESTS,
                "max_thread_messages": MAX_THREAD_MESSAGES,
                "max_workers": MAX_WORKERS
            }
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

@app.route("/export/conversations", methods=['GET'])
def export_conversations():
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    try:
        all_data = []
        cursor = '0'
        
        while True:
            cursor, keys = redis_db.scan(cursor, match="h:*", count=30)
            
            for key in keys:
                student_id = key.split(":")[1]
                messages = redis_db.lrange(key, 0, -1)
                
                student_msgs = []
                for msg_json in messages:
                    try:
                        msg = json.loads(msg_json)
                        # é‚„åŸæ ¼å¼
                        student_msgs.append({
                            "student_id": msg["s"],
                            "role": "user" if msg["r"] == "u" else "assistant",
                            "content": msg["c"],
                            "timestamp": msg["t"]
                        })
                    except:
                        continue
                
                if student_msgs:
                    all_data.append({
                        "student_id": student_id,
                        "total_messages": len(student_msgs),
                        "messages": student_msgs[:50]
                    })
            
            if cursor == '0':
                break
        
        return jsonify({
            "export_time": datetime.now().isoformat(),
            "total_students": len(all_data),
            "data": all_data
        }), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500
@app.route("/test-openai", methods=['POST'])
def test_openai():
    """æ¸¬è©¦ç”¨çš„ç«¯é»ï¼Œç¢ºä¿çœŸçš„å‘¼å« OpenAI"""
    try:
        data = request.json
        user_id = data.get('user_id', 'test_user')
        message = data.get('message', 'Hello, please give me a real response.')
        
        print(f"ğŸ” Test endpoint called by {user_id}: {message[:50]}")
        
        # ç¢ºä¿é€™æ˜¯éœ€è¦çœŸå¯¦å›æ‡‰çš„æ¸¬è©¦
        wait_for_real = data.get('wait_for_real_response', False)
        
        if wait_for_real:
            print(f"â³ Making real OpenAI call for {user_id}")
            # å¯¦éš›å‘¼å« GPT_response
            response = GPT_response(user_id, message)
            print(f"âœ… OpenAI responded to {user_id}")
        else:
            # å¿«é€Ÿæ¸¬è©¦æ¨¡å¼
            response = "Test response (quick mode)"
        
        return jsonify({
            "success": True,
            "user_id": user_id,
            "response": response[:500] if response else "",
            "response_length": len(response) if response else 0,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        print(f"âŒ Test endpoint error: {e}")
        traceback.print_exc()
        return jsonify({
            "success": False, 
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500
# --- 8. å•Ÿå‹• ---
if __name__ == "__main__":
    print(f"ğŸš€ Starting with {MAX_WORKERS} workers, {MAX_CONCURRENT_REQUESTS} concurrent limit")
    print(f"ğŸ’¾ Memory optimized: {MAX_THREAD_MESSAGES} messages per thread")
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, threaded=True)
