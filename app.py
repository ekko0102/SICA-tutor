from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os
import openai
import time
import traceback
import requests
import redis
import json
from datetime import datetime
import hashlib
import threading
import concurrent.futures
import uuid
import queue
from collections import defaultdict
try:
    from disk_config import disk_storage
    DISK_ENABLED = True
    print(f"âœ… Disk storage enabled at: /data")
except ImportError as e:
    DISK_ENABLED = False
    print(f"âš ï¸  Disk storage disabled: {e}")
except Exception as e:
    DISK_ENABLED = False
    print(f"âš ï¸  Disk storage disabled (other error): {e}")


app = Flask(__name__)

# =============================================
# é›¶å¤±æ•—ä¿è­‰ç³»çµ±
# =============================================
class GuaranteedResponseSystem:
    """ä¿è­‰å›æ‡‰ç³»çµ± - æ°¸ä¸å¤±æ•—ï¼ŒæŒçºŒé‡è©¦ç›´åˆ°æˆåŠŸ"""
    
    def __init__(self, max_workers=5):
        self.pending_queue = queue.Queue()
        self.processing_tasks = {}
        self.completed_tasks = {}
        self.task_status = {}
        self.max_workers = max_workers
        self.loading_sessions = {}
        self.lock = threading.Lock()
        self.workers = []  # æ–°å¢ï¼šå„²å­˜ worker åƒè€ƒ
        self.is_running = True  # æ–°å¢ï¼šé‹è¡Œæ¨™è¨˜
        
        print(f"ğŸ› ï¸  Initializing {max_workers} workers...")
        
        # å•Ÿå‹•å·¥ä½œè€…åŸ·è¡Œç·’
        for i in range(max_workers):
            worker = threading.Thread(
                target=self._worker_loop,
                args=(i,),
                daemon=True,
                name=f"Worker-{i}"
            )
            worker.start()
            self.workers.append(worker)
            print(f"âœ… Worker {i} started (ID: {worker.ident})")
        
        # å•Ÿå‹•ç›£æ§åŸ·è¡Œç·’
        monitor = threading.Thread(
            target=self._monitor_loop,
            daemon=True,
            name="Task-Monitor"
        )
        monitor.start()
        
        # å•Ÿå‹•è¼‰å…¥å‹•ç•«ç®¡ç†åŸ·è¡Œç·’
        loading_manager = threading.Thread(
            target=self._loading_manager_loop,
            daemon=True,
            name="Loading-Manager"
        )
        loading_manager.start()
        
        print(f"ğŸš€ All {max_workers} workers initialized and ready")
    
    def _worker_loop(self, worker_id):
        """å·¥ä½œè€…åŸ·è¡Œç·’ - æ°¸ä¸åœæ­¢ï¼ŒæŒçºŒè™•ç†ä»»å‹™"""
        print(f"ğŸ‘· Worker {worker_id} loop STARTED")
        
        while self.is_running:
            try:
                print(f"â³ Worker {worker_id} waiting for task...")
                
                # å¾éšŠåˆ—ç²å–ä»»å‹™ï¼ˆé˜»å¡ç­‰å¾…ï¼Œtimeout=1ç§’ä»¥ä¾¿æª¢æŸ¥é‹è¡Œç‹€æ…‹ï¼‰
                try:
                    task_data = self.pending_queue.get(timeout=1)
                except queue.Empty:
                    continue  # å¦‚æœéšŠåˆ—ç©ºï¼Œç¹¼çºŒç­‰å¾…
                
                if task_data is None:  # åœæ­¢ä¿¡è™Ÿ
                    break
                
                task_id, task = task_data
                
                print(f"ğŸ‘· Worker {worker_id} START processing task {task_id[:8]} "
                      f"for {task['user_id'][:8]}")
                
                # è™•ç†ä»»å‹™ï¼ˆç„¡é™é‡è©¦ç›´åˆ°æˆåŠŸï¼‰
                self._process_with_infinite_retry(worker_id, task_id, task)
                
                # æ¨™è¨˜éšŠåˆ—å®Œæˆ
                self.pending_queue.task_done()
                
                print(f"ğŸ‘· Worker {worker_id} FINISHED task {task_id[:8]}")
                
            except Exception as e:
                print(f"âŒ Worker {worker_id} loop error: {str(e)[:100]}")
                traceback.print_exc()
                time.sleep(5)  # éŒ¯èª¤å¾Œä¼‘æ¯5ç§’
        
        print(f"ğŸ‘· Worker {worker_id} loop STOPPED")
    
    def _process_with_infinite_retry(self, worker_id, task_id, task):
        """ç„¡é™é‡è©¦ç›´åˆ°æˆåŠŸ"""
        user_id = task['user_id']
        text = task['text']
        reply_token = task.get('reply_token')
        
        max_retries = 20  # æœ€å¤šé‡è©¦æ¬¡æ•¸ï¼ˆå¯¦éš›ä¸Šæœƒä¸€ç›´é‡è©¦ï¼‰
        backoff_base = 5   # é€€é¿åŸºç¤æ™‚é–“
        
        for attempt in range(max_retries + 100):  # å¯¦éš›ä¸Šæœƒä¸€ç›´å˜—è©¦
            try:
                # æ›´æ–°é‡è©¦æ¬¡æ•¸
                with self.lock:
                    if task_id in self.task_status:
                        self.task_status[task_id]['retry_count'] = attempt
                        self.task_status[task_id]['last_attempt'] = datetime.now().isoformat()
                
                print(f"ğŸ”„ Worker {worker_id} attempt {attempt+1} for task {task_id[:8]}")
                
                # ç™¼é€é€²åº¦æ›´æ–°ï¼ˆæ¯3æ¬¡é‡è©¦æ›´æ–°ä¸€æ¬¡ï¼‰
                if attempt % 3 == 0:
                    self._send_progress_update(
                        user_id, 
                        f"ğŸ¤– AI is thinking... (attempt {attempt+1})"
                    )
                
                # å˜—è©¦ç²å–AIå›æ‡‰
                response = self._call_gpt_with_patience(user_id, text, attempt)
                
                if response and len(response.strip()) > 5:  # æœ‰æ•ˆå›æ‡‰
                    print(f"âœ… Task {task_id[:8]} completed after {attempt+1} attempts")
                    
                    # å„²å­˜çµæœ
                    with self.lock:
                        self.completed_tasks[task_id] = {
                            'response': response,
                            'completed_at': datetime.now().isoformat(),
                            'attempts': attempt + 1,
                            'user_id': user_id
                        }
                        if task_id in self.processing_tasks:
                            del self.processing_tasks[task_id]
                        self.task_status[task_id] = {
                            'status': 'completed',
                            'completed_at': datetime.now().isoformat()
                        }
                    
                    # ç™¼é€æœ€çµ‚å›æ‡‰
                    success = self._deliver_final_response(user_id, response, reply_token)
                    
                    if success:
                        # åœæ­¢è¼‰å…¥å‹•ç•«
                        self._stop_loading_animation(user_id)
                        return True
                    else:
                        print(f"âš ï¸ Delivery failed for task {task_id[:8]}, will retry...")
                
                # å¦‚æœå¤±æ•—ï¼Œç­‰å¾…å¾Œé‡è©¦
                wait_time = min(backoff_base * (1.5 ** attempt), 300)  # æŒ‡æ•¸é€€é¿ï¼Œæœ€å¤§5åˆ†é˜
                print(f"â³ Waiting {wait_time:.1f}s before retry {attempt+2} for task {task_id[:8]}")
                time.sleep(wait_time)
                
            except Exception as e:
                print(f"âŒ Attempt {attempt+1} failed: {str(e)[:100]}")
                time.sleep(min(30, 5 * (attempt + 1)))  # éŒ¯èª¤ç­‰å¾…
    
    def _call_gpt_with_patience(self, user_id, text, attempt):
        """æœ‰è€å¿ƒåœ°å‘¼å«GPTï¼Œé©æ‡‰æ€§è¶…æ™‚"""
        try:
            # æ ¹æ“šå˜—è©¦æ¬¡æ•¸èª¿æ•´è¶…æ™‚
            timeout = min(60, 10 + attempt * 5)  # é€æ¼¸å¢åŠ è¶…æ™‚
            
            # ä½¿ç”¨æ‚¨çš„ç¾æœ‰GPT_responseå‡½æ•¸
            return GPT_response_direct(user_id, text)
            
        except Exception as e:
            print(f"GPT call failed: {e}")
            return None
    
    def _send_progress_update(self, user_id, message):
        """ç™¼é€é€²åº¦æ›´æ–°ï¼ˆä½¿ç”¨push_messageï¼‰"""
        try:
            # åªç™¼é€é‡è¦æ›´æ–°ï¼Œé¿å…é¨·æ“¾
            line_bot_api.push_message(
                user_id,
                TextSendMessage(text=message)
            )
            return True
        except Exception as e:
            print(f"Progress update failed: {e}")
            return False
    
    def _deliver_final_response(self, user_id, response, reply_token=None):
        """ç™¼é€æœ€çµ‚å›æ‡‰"""
        try:
            # ç¢ºä¿å›æ‡‰ä¸æœƒå¤ªé•·
            if len(response) > 3000:
                response = response[:3000] + "\n\n[è¨Šæ¯å·²æˆªæ–·]"
            
            # å˜—è©¦ä½¿ç”¨reply_tokenï¼ˆå¦‚æœé‚„æœ‰æ•ˆï¼‰
            if reply_token:
                try:
                    line_bot_api.reply_message(
                        reply_token,
                        TextSendMessage(text=response)
                    )
                    return True
                except:
                    pass  # reply_tokenå¯èƒ½å·²éæœŸ
            
            # ä½¿ç”¨push_messageä½œç‚ºå‚™ç”¨
            line_bot_api.push_message(
                user_id,
                TextSendMessage(text=response)
            )
            return True
            
        except Exception as e:
            print(f"Final delivery failed: {e}")
            return False
    
    def _start_loading_animation(self, user_id):
        """é–‹å§‹è¼‰å…¥å‹•ç•«"""
        try:
            with self.lock:
                if user_id not in self.loading_sessions:
                    send_loading(user_id)
                    self.loading_sessions[user_id] = {
                        'started_at': time.time(),
                        'last_restart': time.time()
                    }
        except Exception as e:
            print(f"Failed to start loading: {e}")
    
    def _stop_loading_animation(self, user_id):
        """åœæ­¢è¼‰å…¥å‹•ç•«"""
        try:
            with self.lock:
                if user_id in self.loading_sessions:
                    stop_loading(user_id)
                    del self.loading_sessions[user_id]
        except Exception as e:
            print(f"Failed to stop loading: {e}")
    
    def _loading_manager_loop(self):
        """ç®¡ç†è¼‰å…¥å‹•ç•«ï¼Œå®šæœŸé‡å•Ÿé¿å…è¶…æ™‚"""
        while True:
            try:
                time.sleep(5)  # æ¯5ç§’æª¢æŸ¥ä¸€æ¬¡
                
                with self.lock:
                    current_time = time.time()
                    users_to_restart = []
                    
                    for user_id, session in list(self.loading_sessions.items()):
                        # å¦‚æœè¼‰å…¥å‹•ç•«è¶…é8ç§’ï¼Œéœ€è¦é‡å•Ÿï¼ˆLINEé™åˆ¶10ç§’ï¼‰
                        if current_time - session['last_restart'] > 8:
                            users_to_restart.append(user_id)
                    
                    # é‡å•Ÿè¼‰å…¥å‹•ç•«
                    for user_id in users_to_restart:
                        try:
                            # å…ˆåœæ­¢
                            stop_loading(user_id)
                            time.sleep(0.5)
                            # å†é–‹å§‹
                            send_loading(user_id)
                            self.loading_sessions[user_id]['last_restart'] = current_time
                            print(f"ğŸ”„ Restarted loading animation for {user_id[:8]}")
                        except:
                            pass
                            
            except Exception as e:
                print(f"Loading manager error: {e}")
                time.sleep(10)
    
    def _monitor_loop(self):
        """ç›£æ§å¾ªç’°ï¼Œæª¢æŸ¥åœæ»¯çš„ä»»å‹™"""
        while True:
            try:
                time.sleep(30)  # æ¯30ç§’æª¢æŸ¥ä¸€æ¬¡
                
                with self.lock:
                    current_time = time.time()
                    stale_tasks = []
                    
                    for task_id, status in list(self.task_status.items()):
                        if status.get('status') == 'processing':
                            # æª¢æŸ¥ä»»å‹™æ˜¯å¦è™•ç†è¶…é10åˆ†é˜
                            started_str = status.get('started_at')
                            if started_str:
                                try:
                                    started = datetime.fromisoformat(started_str)
                                    age = (datetime.now() - started).total_seconds()
                                    
                                    if age > 600:  # 10åˆ†é˜
                                        stale_tasks.append(task_id)
                                except:
                                    pass
                    
                    # é‡å•Ÿåœæ»¯çš„ä»»å‹™
                    for task_id in stale_tasks:
                        print(f"âš ï¸ Restarting stale task {task_id[:8]}")
                        if task_id in self.processing_tasks:
                            task = self.processing_tasks[task_id]
                            # é‡æ–°åŠ å…¥éšŠåˆ—
                            self.submit_task(task['user_id'], task['text'], task.get('reply_token'))
                            
            except Exception as e:
                print(f"Monitor error: {e}")
    
    def submit_task(self, user_id, text, reply_token=None):
        """æäº¤æ–°ä»»å‹™åˆ°é›¶å¤±æ•—ç³»çµ±"""
        task_id = str(uuid.uuid4())[:12]
        
        task = {
            'task_id': task_id,
            'user_id': user_id,
            'text': text,
            'reply_token': reply_token,
            'submitted_at': datetime.now().isoformat()
        }
        
        # åŠ å…¥éšŠåˆ—
        self.pending_queue.put((task_id, task))
        
        # ç«‹å³é–‹å§‹è¼‰å…¥å‹•ç•«
        self._start_loading_animation(user_id)
        
        print(f"ğŸ“¥ Task {task_id[:8]} submitted for {user_id[:8]}, "
              f"queue size: {self.pending_queue.qsize()}")
        
        return task_id
    
    def get_stats(self):
        """ç²å–ç³»çµ±çµ±è¨ˆ"""
        with self.lock:
            return {
                'queue_size': self.pending_queue.qsize(),
                'processing_tasks': len(self.processing_tasks),
                'completed_tasks': len(self.completed_tasks),
                'loading_sessions': len(self.loading_sessions),
                'timestamp': datetime.now().isoformat()
            }

# å»ºç«‹é›¶å¤±æ•—ç³»çµ±å¯¦ä¾‹
zero_failure_system = GuaranteedResponseSystem(max_workers=5)

# =============================================
# åŸæœ‰éšŠåˆ—ç³»çµ±ï¼ˆä¿ç•™ä½†æ”¹ç‚ºä½¿ç”¨é›¶å¤±æ•—ç³»çµ±ï¼‰
# =============================================

class OpenAIBatchProcessor:
    """æ‰¹é‡è™•ç† OpenAI è«‹æ±‚ï¼Œé¿å…è¶…è¼‰"""
    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self.semaphore = threading.Semaphore(max_concurrent)
        self.request_count = 0
        
    def process(self, user_id, text):
        """è™•ç†å–®ä¸€è«‹æ±‚ - ç¾åœ¨ç›´æ¥ä½¿ç”¨é›¶å¤±æ•—ç³»çµ±"""
        self.request_count += 1
        req_num = self.request_count
        
        print(f"[{req_num}] Request from {user_id[:8]} via batch processor")
        
        # ç›´æ¥æäº¤åˆ°é›¶å¤±æ•—ç³»çµ±
        task_id = zero_failure_system.submit_task(user_id, text)
        
        # ç­‰å¾…ä»»å‹™å®Œæˆï¼ˆæœ€å¤šç­‰å¾…ä¸€æ®µæ™‚é–“ï¼‰
        start_time = time.time()
        max_wait = 300  # æœ€å¤šç­‰å¾…5åˆ†é˜
        
        while time.time() - start_time < max_wait:
            # æª¢æŸ¥ä»»å‹™æ˜¯å¦å·²å®Œæˆ
            if task_id in zero_failure_system.completed_tasks:
                result = zero_failure_system.completed_tasks[task_id]['response']
                print(f"[{req_num}] Task {task_id[:8]} completed via zero-failure system")
                return result
            
            time.sleep(1)
        
        # å¦‚æœè¶…æ™‚ï¼Œè¿”å›ç­‰å¾…è¨Šæ¯
        return "Your request is still processing. You'll receive the answer soon!"

# å»ºç«‹å…¨åŸŸè™•ç†å™¨
openai_processor = OpenAIBatchProcessor(max_concurrent=5)

# =============================================
# åˆå§‹åŒ–è¨­å®š
# =============================================

redis_url = os.getenv('REDIS_URL')
if not redis_url:
    raise ValueError("REDIS_URL is not set")
redis_db = redis.StrictRedis.from_url(redis_url, decode_responses=True,
                                     max_connections=20)  # å¢åŠ é€£æ¥æ•¸

line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))

openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY is not set")

# æ”¹ç‚ºï¼š
try:
    # ç°¡åŒ–åˆå§‹åŒ–ï¼Œé¿å…åƒæ•¸å•é¡Œ
    client = openai.OpenAI(api_key=openai_api_key)
except Exception as e:
    print(f"âŒ OpenAI client initialization failed: {e}")
    # å¦‚æœåˆå§‹åŒ–å¤±æ•—ï¼Œå»ºç«‹ä¸€å€‹ç°¡å–®çš„ client
    class SimpleOpenAIClient:
        def __init__(self, api_key):
            self.api_key = api_key
    
    client = SimpleOpenAIClient(api_key=openai_api_key)
ASSISTANT_ID = os.getenv('ASSISTANT_ID') 

# =============================================
# å„ªåŒ–è¨­å®š
# =============================================

MAX_THREAD_MESSAGES = 15
MAX_MESSAGE_LENGTH = 2000
MAX_CONCURRENT_REQUESTS = 5
MAX_WORKERS = 3
REQUEST_TIMEOUT = 60  # å¢åŠ åˆ°60ç§’ï¼Œè®“AIæœ‰æ›´å¤šæ™‚é–“
REDIS_MAX_PER_STUDENT = 80

# =============================================
# è³‡æºç›£æ§
# =============================================

class ResourceMonitor:
    def __init__(self):
        self.request_count = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def increment(self):
        with self.lock:
            self.request_count += 1
    
    def get_stats(self):
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                "total_requests": self.request_count,
                "requests_per_minute": self.request_count / (uptime / 60) if uptime > 0 else 0,
                "uptime_hours": round(uptime / 3600, 2)
            }

monitor = ResourceMonitor()

# =============================================
# å„ªåŒ–è³‡æ–™å„²å­˜
# =============================================

def generate_anonymous_id(user_id):
    return hashlib.md5(user_id.encode()).hexdigest()[:10]

def save_message_optimized(user_id, role, content):
    """ç¯€çœè¨˜æ†¶é«”çš„å„²å­˜æ–¹å¼"""
    try:
        student_id = generate_anonymous_id(user_id)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        
        # å£“ç¸®å…§å®¹
        if len(content) > MAX_MESSAGE_LENGTH:
            keep = MAX_MESSAGE_LENGTH // 2
            content = content[:keep] + "..." + content[-keep//2:]
        
        # æœ€å°åŒ–è³‡æ–™çµæ§‹
        message_data = {
            "s": student_id,
            "r": role[0],  # 'u' æˆ– 'a'
            "c": content,
            "t": timestamp
        }
        
        # ä½¿ç”¨æ›´çŸ­çš„éµå
        key = f"h:{student_id}"
        redis_db.rpush(key, json.dumps(message_data, separators=(',', ':')))
        
        # åš´æ ¼æ§åˆ¶æ­·å²é•·åº¦
        if redis_db.llen(key) > REDIS_MAX_PER_STUDENT:
            redis_db.ltrim(key, -REDIS_MAX_PER_STUDENT, -1)
        
        return True
    except Exception as e:
        print(f"Save optimized error: {e}")
        return False

# =============================================
# GPT_response å‡½æ•¸ - ç§»é™¤æ‰€æœ‰éŒ¯èª¤è¨Šæ¯
# =============================================

def GPT_response_direct(user_id, text):
    """ç›´æ¥å‘¼å« OpenAI çš„ç‰ˆæœ¬ - æ°¸ä¸è¿”å›éŒ¯èª¤è¨Šæ¯"""
    monitor.increment()
    
    # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯
    save_message_optimized(user_id, "user", text[:1500])
    
    # ç§»é™¤æ‰€æœ‰è¶…æ™‚æª¢æŸ¥å’ŒéŒ¯èª¤è¨Šæ¯è¿”å›
    try:
        # å–å¾—æˆ–å‰µå»º thread
        thread_id = redis_db.get(f"t:{user_id}")
        
        # æ™ºèƒ½æ¸…ç† thread
        if thread_id:
            try:
                messages = client.beta.threads.messages.list(
                    thread_id=thread_id,
                    limit=MAX_THREAD_MESSAGES + 2,
                    timeout=10.0  # å¢åŠ è¶…æ™‚
                )
                
                if len(messages.data) > MAX_THREAD_MESSAGES:
                    print(f"Cleaning thread ({len(messages.data)} -> 8)")
                    
                    keep_messages = []
                    for msg in messages.data[-8:]:
                        if hasattr(msg, 'content') and msg.content:
                            content = msg.content[0].text.value
                            if len(content) > 800:
                                content = content[:800] + "..."
                            keep_messages.append({
                                "role": msg.role,
                                "content": content
                            })
                    
                    if keep_messages:
                        new_thread = client.beta.threads.create(
                            messages=keep_messages
                        )
                        thread_id = new_thread.id
                        redis_db.setex(f"t:{user_id}", 3600, thread_id)  # å¢åŠ åˆ°1å°æ™‚
                    else:
                        thread_id = None
                        
            except Exception as e:
                print(f"Thread cleanup error: {e}")
                thread_id = None
        
        # å‰µå»ºæ–° thread
        if not thread_id:
            thread = client.beta.threads.create(
                messages=[{"role": "user", "content": text[:1500]}]
            )
            thread_id = thread.id
            redis_db.setex(f"t:{user_id}", 3600, thread_id)
        
        # åŠ å…¥æ–°è¨Šæ¯
        else:
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=text[:1500],
                timeout=10.0
            )
        
        # åŸ·è¡ŒåŠ©ç† - å¢åŠ è¶…æ™‚
        run = client.beta.threads.runs.create(
            thread_id=thread_id, 
            assistant_id=ASSISTANT_ID,
            timeout=30.0
        )
        
        # è€å¿ƒç­‰å¾…å®Œæˆ - ç„¡è¶…æ™‚é™åˆ¶
        while run.status != "completed":
            if run.status in ["failed", "cancelled", "expired"]:
                error_msg = run.last_error.message[:100] if run.last_error else "Unknown"
                print(f"Run failed: {error_msg}")
                # é‡æ–°é–‹å§‹
                run = client.beta.threads.runs.create(
                    thread_id=thread_id, 
                    assistant_id=ASSISTANT_ID,
                    timeout=30.0
                )
            
            time.sleep(1)  # æ¯ç§’æª¢æŸ¥ä¸€æ¬¡
            run = client.beta.threads.runs.retrieve(
                thread_id=thread_id, 
                run_id=run.id,
                timeout=10.0
            )
        
        # å–å¾—å›è¦†
        messages = client.beta.threads.messages.list(
            thread_id=thread_id,
            order="desc",
            limit=1,
            timeout=10.0
        )
        
        if not messages.data or not messages.data[0].content:
            # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›é è¨­å›æ‡‰è€Œä¸æ˜¯éŒ¯èª¤
            ai_reply = "I've received your question and I'm thinking about it. Please wait a moment."
        else:
            ai_reply = messages.data[0].content[0].text.value
        
        # å„²å­˜å›è¦†
        save_message_optimized(user_id, "assistant", ai_reply[:2000])
        
        # å®šæœŸæ¸…ç†
        conv_key = f"c:{user_id}"
        conv_count = redis_db.incr(conv_key)
        redis_db.expire(conv_key, 3600)
        
        if conv_count >= 10:  # å¢åŠ åˆ°10æ¬¡å°è©±æ‰æ¸…ç†
            redis_db.delete(conv_key)
            redis_db.delete(f"t:{user_id}")
            print(f"Periodic cleanup for {user_id[:8]}")
        
        return ai_reply
        
    except Exception as e:
        print(f"GPT_response error: {e}")
        # è¿”å›ä¸­æ€§å›æ‡‰ï¼Œè€Œä¸æ˜¯éŒ¯èª¤è¨Šæ¯
        return "I'm currently processing your request. Please give me a moment to think."

def GPT_response(user_id, text):
    """æ–°çš„ GPT_responseï¼Œä½¿ç”¨éšŠåˆ—è™•ç†"""
    try:
        print(f"ğŸ“¨ Received request from {user_id[:8]}: {text[:30]}...")
        
        # ä½¿ç”¨æ‰¹è™•ç†å™¨ï¼ˆæœƒè½‰åˆ°é›¶å¤±æ•—ç³»çµ±ï¼‰
        result = openai_processor.process(user_id, text)
        
        print(f"âœ… Response ready for {user_id[:8]}")
        return result
        
    except Exception as e:
        print(f"âŒ Error in queued GPT_response: {e}")
        # è¿”å›ä¸­æ€§è¨Šæ¯
        return "Processing your question now. You'll receive an answer shortly."

# =============================================
# LINE è¼‰å…¥å‹•ç•«å‡½æ•¸
# =============================================

def send_loading(chat_id):
    """ç™¼é€è¼‰å…¥å‹•ç•«"""
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/start'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id, "loadingSeconds": 9}
        response = requests.post(url, headers=headers, json=data, timeout=3)
        if response.status_code == 200:
            print(f"â–¶ï¸ Started loading animation for {chat_id[:8]}")
        return True
    except Exception as e:
        print(f"Failed to start loading: {e}")
        return False

def stop_loading(chat_id):
    """åœæ­¢è¼‰å…¥å‹•ç•«"""
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/stop'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id}
        response = requests.post(url, headers=headers, json=data, timeout=3)
        if response.status_code == 200:
            print(f"â¹ï¸ Stopped loading animation for {chat_id[:8]}")
        return True
    except Exception as e:
        print(f"Failed to stop loading: {e}")
        return False

# =============================================
# LINE Webhook è™•ç† - ç°¡åŒ–ç‰ˆæœ¬
# =============================================

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
        return 'OK', 200
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        print(f"Callback error: {e}")
        return 'OK', 200

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg_id = event.message.id
    user_msg = event.message.text
    user_id = event.source.user_id
    reply_token = event.reply_token

    # é˜²é‡è¤‡è™•ç†
    if redis_db.get(f"p:{msg_id}"):
        return 
    redis_db.setex(f"p:{msg_id}", 20, "1")

    # ç¾¤çµ„éæ¿¾
    if event.source.type == 'group':
        if 'bot' not in user_msg.lower() and '@AI' not in user_msg:
            redis_db.delete(f"p:{msg_id}")
            return
    
    # é‡è¦ï¼šä¸ç™¼é€ä»»ä½•æ–‡å­—å›è¦†ï¼Œåªå•Ÿå‹•è¼‰å…¥å‹•ç•«
    # é›¶å¤±æ•—ç³»çµ±æœƒè‡ªå‹•å•Ÿå‹•è¼‰å…¥å‹•ç•«
    
    # ç«‹å³æäº¤ä»»å‹™åˆ°é›¶å¤±æ•—ç³»çµ±
    print(f"ğŸ¯ Submitting message from {user_id[:8]}: {user_msg[:50]}...")
    
    # ä½¿ç”¨é›¶å¤±æ•—ç³»çµ±è™•ç†
    task_id = zero_failure_system.submit_task(user_id, user_msg, reply_token)
    
    print(f"âœ… Task {task_id[:8]} submitted to zero-failure system for {user_id[:8]}")
    
    # æ³¨æ„ï¼šé€™è£¡ä¸ç™¼é€ä»»ä½•æ–‡å­—å›è¦†ï¼Œåªæœ‰è¼‰å…¥å‹•ç•«
    # æ‰€æœ‰å›æ‡‰å°‡ç”±é›¶å¤±æ•—ç³»çµ±é€é push_message ç™¼é€

# =============================================
# ç®¡ç†ç«¯é» - å¢å¼·ç‰ˆæœ¬
# =============================================

@app.route("/health", methods=['GET'])
def health_check():
    try:
        redis_db.ping()
        stats = monitor.get_stats()
        zero_failure_stats = zero_failure_system.get_stats()
        
        return jsonify({
            "status": "healthy",
            "resources": stats,
            "zero_failure_system": zero_failure_stats,
            "config": {
                "max_concurrent": MAX_CONCURRENT_REQUESTS,
                "max_thread_messages": MAX_THREAD_MESSAGES,
                "max_workers": MAX_WORKERS
            }
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

@app.route("/processor-stats", methods=['GET'])
def processor_stats():
    """æŸ¥çœ‹è™•ç†å™¨ç‹€æ…‹"""
    zero_failure_stats = zero_failure_system.get_stats()
    
    stats = {
        "max_concurrent": openai_processor.max_concurrent,
        "total_requests": openai_processor.request_count,
        "current_semaphore_value": openai_processor.semaphore._value,
        "active_requests": openai_processor.max_concurrent - openai_processor.semaphore._value,
        "zero_failure_system": zero_failure_stats,
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(stats)

@app.route("/zero-failure-stats", methods=['GET'])
def zero_failure_stats():
    """æŸ¥çœ‹é›¶å¤±æ•—ç³»çµ±è©³ç´°ç‹€æ…‹"""
    stats = zero_failure_system.get_stats()
    
    # æ·»åŠ è©³ç´°è³‡è¨Š
    detailed_stats = {
        **stats,
        "system_info": {
            "description": "Zero-failure guaranteed response system",
            "max_workers": zero_failure_system.max_workers,
            "guarantee": "Infinite retry until success",
            "loading_animation": "Auto-managed with periodic restart"
        },
        "status": "operational"
    }
    
    return jsonify(detailed_stats)

@app.route("/export/conversations", methods=['GET'])
def export_conversations():
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    try:
        all_data = []
        cursor = '0'
        
        while True:
            cursor, keys = redis_db.scan(cursor, match="h:*", count=30)
            
            for key in keys:
                student_id = key.split(":")[1]
                messages = redis_db.lrange(key, 0, -1)
                
                student_msgs = []
                for msg_json in messages:
                    try:
                        msg = json.loads(msg_json)
                        student_msgs.append({
                            "student_id": msg["s"],
                            "role": "user" if msg["r"] == "u" else "assistant",
                            "content": msg["c"],
                            "timestamp": msg["t"]
                        })
                    except:
                        continue
                
                if student_msgs:
                    all_data.append({
                        "student_id": student_id,
                        "total_messages": len(student_msgs),
                        "messages": student_msgs[:50]
                    })
            
            if cursor == '0':
                break
        
        return jsonify({
            "export_time": datetime.now().isoformat(),
            "total_students": len(all_data),
            "data": all_data
        }), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/test-simple", methods=['POST', 'GET'])
def test_simple():
    """æ¥µç°¡æ¸¬è©¦ç«¯é»"""
    try:
        print("âœ… /test-simple endpoint called")
        
        if request.method == 'GET':
            return jsonify({
                "status": "ready",
                "endpoint": "/test-simple",
                "message": "Use POST to test OpenAI",
                "zero_failure_system": "enabled"
            }), 200
        
        # POST è«‹æ±‚ï¼šå¯¦éš›æ¸¬è©¦ OpenAI
        data = request.json or {}
        user_id = data.get('user_id', 'test_user_001')
        message = data.get('message', 'Hello, please respond.')
        
        print(f"ğŸ¯ Testing OpenAI for user: {user_id}")
        print(f"ğŸ“ Message: {message}")
        
        # ä½¿ç”¨é›¶å¤±æ•—ç³»çµ±
        task_id = zero_failure_system.submit_task(user_id, message)
        
        # ç­‰å¾…çµæœï¼ˆæœ€å¤š30ç§’ï¼‰
        start_time = time.time()
        while time.time() - start_time < 30:
            if task_id in zero_failure_system.completed_tasks:
                response_text = zero_failure_system.completed_tasks[task_id]['response']
                duration = time.time() - start_time
                
                print(f"âœ… Zero-failure response received in {duration:.1f}s")
                print(f"ğŸ“„ Response: {response_text[:100]}...")
                
                return jsonify({
                    "success": True,
                    "task_id": task_id,
                    "user_id": user_id,
                    "response": response_text[:1000],
                    "response_length": len(response_text),
                    "duration_seconds": round(duration, 2),
                    "via_zero_failure": True,
                    "timestamp": datetime.now().isoformat()
                }), 200
            
            time.sleep(0.5)
        
        # è¶…æ™‚
        return jsonify({
            "success": False,
            "task_id": task_id,
            "error": "Timeout waiting for response",
            "message": "Task is still processing in zero-failure system",
            "timestamp": datetime.now().isoformat()
        }), 408
        
    except Exception as e:
        print(f"âŒ Error in /test-simple: {e}")
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500

# =============================================
# å•Ÿå‹•
# =============================================

if __name__ == "__main__":
    print(f"""
    ========================================
    ğŸš€ ZERO-FAILURE LINE BOT STARTING
    ========================================
    Features:
    âœ… Zero-failure guaranteed response system
    âœ… Auto-managed loading animations
    âœ… No error messages to users
    âœ… Infinite retry until success
    
    OpenAI Queue: {openai_processor.max_concurrent} concurrent
    Max Workers: {MAX_WORKERS}
    Disk Storage: {'âœ… Enabled' if DISK_ENABLED else 'âŒ Disabled'}
    ========================================
    """)
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, threaded=True)
