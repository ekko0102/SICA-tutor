from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os
import openai
import time
import traceback
import requests
import redis
import json
from datetime import datetime
import hashlib
import threading
import concurrent.futures
import uuid

app = Flask(__name__)

# =============================================
# 1. å°å…¥ç¡¬ç¢Ÿå„²å­˜
# =============================================
try:
    from disk_config import disk_storage
    DISK_ENABLED = True
    print(f"âœ… Disk storage enabled at: {disk_storage.mount_path}")
except ImportError as e:
    DISK_ENABLED = False
    print(f"âš ï¸  Disk storage disabled: {e}")

# =============================================
# 2. ç¾æœ‰çš„éšŠåˆ—ç³»çµ±ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
class OpenAIBatchProcessor:
    """æ‰¹é‡è™•ç† OpenAI è«‹æ±‚ï¼Œé¿å…è¶…è¼‰"""
    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self.semaphore = threading.Semaphore(max_concurrent)
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent)
        self.request_count = 0
        
    def process(self, user_id, text):
        """è™•ç†å–®ä¸€è«‹æ±‚"""
        self.request_count += 1
        req_num = self.request_count
        
        print(f"[{req_num}] Request from {user_id[:8]} waiting for semaphore...")
        
        acquired = self.semaphore.acquire(blocking=False)
        if not acquired:
            print(f"[{req_num}] Queue full, waiting...")
            self.semaphore.acquire(blocking=True)
        
        try:
            print(f"[{req_num}] Processing for {user_id[:8]}...")
            result = self._call_gpt_response(user_id, text)
            return result
            
        finally:
            self.semaphore.release()
            print(f"[{req_num}] Completed for {user_id[:8]}")
    
    def _call_gpt_response(self, user_id, text):
        """å‘¼å«ç¾æœ‰çš„ GPT_response å‡½æ•¸"""
        return GPT_response_direct(user_id, text)

# å»ºç«‹å…¨åŸŸè™•ç†å™¨
openai_processor = OpenAIBatchProcessor(max_concurrent=5)

# =============================================
# 3. åˆå§‹åŒ–è¨­å®šï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
redis_url = os.getenv('REDIS_URL')
if not redis_url:
    raise ValueError("REDIS_URL is not set")
redis_db = redis.StrictRedis.from_url(redis_url, decode_responses=True, max_connections=10)

line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))

openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY is not set")

client = openai.OpenAI(api_key=openai_api_key, timeout=25.0)
ASSISTANT_ID = os.getenv('ASSISTANT_ID')

# =============================================
# 4. å„ªåŒ–è¨­å®šï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
MAX_THREAD_MESSAGES = 15
MAX_MESSAGE_LENGTH = 2000
MAX_CONCURRENT_REQUESTS = 5
MAX_WORKERS = 3
REQUEST_TIMEOUT = 12
REDIS_MAX_PER_STUDENT = 80

# =============================================
# 5. è³‡æºç›£æ§ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
class ResourceMonitor:
    def __init__(self):
        self.request_count = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def increment(self):
        with self.lock:
            self.request_count += 1
    
    def get_stats(self):
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                "total_requests": self.request_count,
                "requests_per_minute": self.request_count / (uptime / 60) if uptime > 0 else 0,
                "uptime_hours": round(uptime / 3600, 2)
            }

monitor = ResourceMonitor()

# =============================================
# 6. å„ªåŒ–è³‡æ–™å„²å­˜ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
def generate_anonymous_id(user_id):
    return hashlib.md5(user_id.encode()).hexdigest()[:10]

def save_message_optimized(user_id, role, content):
    """ç¯€çœè¨˜æ†¶é«”çš„å„²å­˜æ–¹å¼"""
    try:
        student_id = generate_anonymous_id(user_id)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        
        if len(content) > MAX_MESSAGE_LENGTH:
            keep = MAX_MESSAGE_LENGTH // 2
            content = content[:keep] + "..." + content[-keep//2:]
        
        message_data = {
            "s": student_id,
            "r": role[0],
            "c": content,
            "t": timestamp
        }
        
        key = f"h:{student_id}"
        redis_db.rpush(key, json.dumps(message_data, separators=(',', ':')))
        
        if redis_db.llen(key) > REDIS_MAX_PER_STUDENT:
            redis_db.ltrim(key, -REDIS_MAX_PER_STUDENT, -1)
        
        return True
    except Exception as e:
        print(f"Save optimized error: {e}")
        return False

# =============================================
# 7. GPT_response å‡½æ•¸ï¼ˆæ–°å¢ç¡¬ç¢Ÿå„²å­˜ï¼‰
# =============================================
def GPT_response_direct(user_id, text):
    """ç›´æ¥å‘¼å« OpenAI çš„ç‰ˆæœ¬ - æ–°å¢ç¡¬ç¢Ÿå„²å­˜"""
    monitor.increment()
    
    try:
        # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯åˆ° Redis
        save_message_optimized(user_id, "user", text[:1500])
        
        # å–å¾—æˆ–å‰µå»º threadï¼ˆä¿æŒåŸé‚è¼¯ï¼‰
        thread_id = redis_db.get(f"t:{user_id}")
        
        if thread_id:
            try:
                messages = client.beta.threads.messages.list(
                    thread_id=thread_id,
                    limit=MAX_THREAD_MESSAGES + 2,
                    timeout=2.0
                )
                
                if len(messages.data) > MAX_THREAD_MESSAGES:
                    print(f"Cleaning thread ({len(messages.data)} -> 8)")
                    
                    keep_messages = []
                    for msg in messages.data[-8:]:
                        if hasattr(msg, 'content') and msg.content:
                            content = msg.content[0].text.value
                            if len(content) > 800:
                                content = content[:800] + "..."
                            keep_messages.append({
                                "role": msg.role,
                                "content": content
                            })
                    
                    if keep_messages:
                        new_thread = client.beta.threads.create(messages=keep_messages)
                        thread_id = new_thread.id
                        redis_db.setex(f"t:{user_id}", 2400, thread_id)
                    else:
                        thread_id = None
                        
            except Exception as e:
                print(f"Thread cleanup error: {e}")
                thread_id = None
        
        if not thread_id:
            thread = client.beta.threads.create(messages=[{"role": "user", "content": text[:1500]}])
            thread_id = thread.id
            redis_db.setex(f"t:{user_id}", 2400, thread_id)
        else:
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=text[:1500],
                timeout=2.0
            )
        
        # åŸ·è¡ŒåŠ©ç†
        run = client.beta.threads.runs.create(
            thread_id=thread_id, 
            assistant_id=ASSISTANT_ID,
            timeout=6.0
        )
        
        # ç­‰å¾…å®Œæˆ
        start = time.time()
        while run.status != "completed":
            if time.time() - start > REQUEST_TIMEOUT:
                return "Processing taking longer than usual. Please try a shorter question."
            
            if run.status in ["failed", "cancelled", "expired"]:
                error_msg = run.last_error.message[:100] if run.last_error else "Unknown"
                print(f"Run failed: {error_msg}")
                break
            
            time.sleep(0.6)
            run = client.beta.threads.runs.retrieve(
                thread_id=thread_id, 
                run_id=run.id,
                timeout=2.0
            )
        
        # å–å¾—å›è¦†
        messages = client.beta.threads.messages.list(
            thread_id=thread_id,
            order="desc",
            limit=1,
            timeout=2.0
        )
        
        if not messages.data or not messages.data[0].content:
            return "No response generated."
            
        ai_reply = messages.data[0].content[0].text.value
        
        # å„²å­˜å›è¦†åˆ° Redis
        save_message_optimized(user_id, "assistant", ai_reply[:2000])
        
        # =============================================
        # æ–°å¢ï¼šå„²å­˜åˆ°ç¡¬ç¢Ÿï¼ˆå¯¦é©—æ•¸æ“šï¼‰
        # =============================================
        if DISK_ENABLED:
            # åœ¨èƒŒæ™¯åŸ·è¡Œï¼Œä¸å½±éŸ¿å›æ‡‰é€Ÿåº¦
            threading.Thread(
                target=save_to_disk_background,
                args=(user_id,),
                daemon=True
            ).start()
        
        return ai_reply
        
    except openai.APITimeoutError:
        return "AI service timeout. Please try again."
        
    except Exception as e:
        print(f"GPT_response error: {e}")
        return "System error. Please try again."

def save_to_disk_background(user_id):
    """èƒŒæ™¯åŸ·è¡Œï¼šå„²å­˜å°è©±åˆ°ç¡¬ç¢Ÿ"""
    try:
        # ç­‰å¾…ä¸€ä¸‹ï¼Œé¿å…å½±éŸ¿ä¸»è¦æµç¨‹
        time.sleep(1)
        
        # å–å¾—å­¸ç”ŸåŒ¿å ID
        student_id = generate_anonymous_id(user_id)
        
        # å¾ Redis å–å¾—å®Œæ•´çš„å°è©±æ­·å²
        key = f"h:{student_id}"
        messages_json = redis_db.lrange(key, 0, -1)
        
        # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
        messages_list = []
        for msg_json in messages_json:
            try:
                msg = json.loads(msg_json)
                messages_list.append({
                    "role": "user" if msg["r"] == "u" else "assistant",
                    "content": msg["c"],
                    "timestamp": msg["t"]
                })
            except:
                continue
        
        # å„²å­˜åˆ°ç¡¬ç¢Ÿ
        if messages_list:
            success = disk_storage.save_student_conversation(student_id, messages_list)
            if success:
                print(f"ğŸ’¾ Disk save successful for {student_id[:8]} ({len(messages_list)} messages)")
        
    except Exception as e:
        print(f"âš ï¸  Background disk save failed: {e}")

def GPT_response(user_id, text):
    """æ–°çš„ GPT_responseï¼Œä½¿ç”¨éšŠåˆ—è™•ç†"""
    try:
        print(f"ğŸ“¨ Received request from {user_id[:8]}: {text[:30]}...")
        
        # ä½¿ç”¨æ‰¹è™•ç†å™¨
        result = openai_processor.process(user_id, text)
        
        print(f"âœ… Response ready for {user_id[:8]}")
        return result
        
    except Exception as e:
        print(f"âŒ Error in queued GPT_response: {e}")
        return f"Processing error: {str(e)[:100]}"

# =============================================
# 8. LINE è™•ç†ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
executor = concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS)

def send_loading(chat_id):
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/start'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id, "loadingSeconds": 9}
        requests.post(url, headers=headers, json=data, timeout=2)
    except:
        pass

def stop_loading(chat_id):
    try:
        url = 'https://api.line.me/v2/bot/chat/loading/stop'
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {os.getenv("CHANNEL_ACCESS_TOKEN")}'
        }
        data = {"chatId": chat_id}
        requests.post(url, headers=headers, json=data, timeout=2)
    except:
        pass

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
        return 'OK', 200
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        print(f"Callback error: {e}")
        return 'OK', 200

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg_id = event.message.id
    user_msg = event.message.text
    user_id = event.source.user_id
    reply_token = event.reply_token

    # é˜²é‡è¤‡è™•ç†
    if redis_db.get(f"p:{msg_id}"):
        return 
    redis_db.setex(f"p:{msg_id}", 20, "1")

    # ç¾¤çµ„éæ¿¾
    if event.source.type == 'group':
        if 'bot' not in user_msg.lower() and '@AI' not in user_msg:
            redis_db.delete(f"p:{msg_id}")
            return
    
    # é¡¯ç¤ºè¼‰å…¥å‹•ç•«
    send_loading(user_id)
    
    # ä½¿ç”¨åŸ·è¡Œç·’è™•ç†
    def process_in_thread():
        try:
            # ä½¿ç”¨ GPT_responseï¼ˆæœƒè‡ªå‹•æ’éšŠï¼‰
            answer = GPT_response(user_id, user_msg)
            
            # åœæ­¢å‹•ç•«
            stop_loading(user_id)
            
            # æª¢æŸ¥é•·åº¦
            if len(answer) > 3000:
                answer = answer[:3000] + "\n\n[Message trimmed]"
            
            # ä½¿ç”¨ push_message
            line_bot_api.push_message(
                user_id,
                TextSendMessage(text=answer)
            )
            
            print(f"ğŸ“¤ Sent reply to {user_id[:8]}")
            
        except Exception as e:
            print(f"Error in process_in_thread: {e}")
            try:
                stop_loading(user_id)
            except:
                pass
    
    # å•Ÿå‹•èƒŒæ™¯åŸ·è¡Œç·’
    thread = threading.Thread(target=process_in_thread)
    thread.daemon = True
    thread.start()

# =============================================
# 9. æ–°å¢ï¼šç¡¬ç¢Ÿç®¡ç†ç«¯é»ï¼ˆå¯¦é©—æ•¸æ“šï¼‰
# =============================================
@app.route("/disk/status", methods=['GET'])
def disk_status():
    """æª¢æŸ¥ç¡¬ç¢Ÿç‹€æ…‹"""
    if not DISK_ENABLED:
        return jsonify({
            "status": "disabled",
            "message": "Disk storage not enabled"
        }), 200
    
    try:
        info = disk_storage.get_disk_info()
        
        if "error" in info:
            return jsonify(info), 500
        
        return jsonify({
            "status": "enabled",
            "disk_info": info,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/disk/export", methods=['GET'])
def disk_export():
    """åŒ¯å‡ºå¯¦é©—æ•¸æ“š"""
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    if not DISK_ENABLED:
        return jsonify({"error": "Disk storage not enabled"}), 400
    
    try:
        format_type = request.args.get('format', 'json')
        
        export_path = disk_storage.export_all_data(format_type)
        
        if not export_path:
            return jsonify({"error": "Export failed"}), 500
        
        if format_type == 'csv':
            # å›å‚³ CSV æª”æ¡ˆä¸‹è¼‰
            with open(export_path, 'r', encoding='utf-8') as f:
                csv_content = f.read()
            
            response = app.response_class(
                response=csv_content,
                status=200,
                mimetype='text/csv',
                headers={
                    'Content-Disposition': 'attachment; filename=experiment_data.csv'
                }
            )
            return response
        
        else:
            # å›å‚³ JSON æ•¸æ“š
            with open(export_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            return jsonify(json_data), 200
            
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/disk/students", methods=['GET'])
def list_students():
    """åˆ—å‡ºæ‰€æœ‰å­¸ç”Ÿçš„å°è©±æª”æ¡ˆ"""
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    if not DISK_ENABLED:
        return jsonify({"error": "Disk storage not enabled"}), 400
    
    try:
        files = disk_storage.get_all_student_files()
        
        return jsonify({
            "total_students": len(files),
            "students": files,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/disk/student/<student_id>", methods=['GET'])
def get_student_data(student_id):
    """å–å¾—ç‰¹å®šå­¸ç”Ÿçš„å°è©±æ•¸æ“š"""
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    if not DISK_ENABLED:
        return jsonify({"error": "Disk storage not enabled"}), 400
    
    try:
        data = disk_storage.get_student_data(student_id)
        
        if not data:
            return jsonify({"error": "Student not found"}), 404
        
        return jsonify(data), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# =============================================
# 10. åŸæœ‰çš„ç®¡ç†ç«¯é»ï¼ˆä¿æŒä¸è®Šï¼‰
# =============================================
@app.route("/health", methods=['GET'])
def health_check():
    try:
        redis_db.ping()
        stats = monitor.get_stats()
        
        # åŠ å…¥ç¡¬ç¢Ÿç‹€æ…‹
        disk_info = {}
        if DISK_ENABLED:
            disk_info = disk_storage.get_disk_info()
        
        return jsonify({
            "status": "healthy",
            "resources": stats,
            "disk_enabled": DISK_ENABLED,
            "disk_info": disk_info if DISK_ENABLED else None,
            "config": {
                "max_concurrent": MAX_CONCURRENT_REQUESTS,
                "max_thread_messages": MAX_THREAD_MESSAGES,
                "max_workers": MAX_WORKERS
            }
        }), 200
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

@app.route("/processor-stats", methods=['GET'])
def processor_stats():
    """æŸ¥çœ‹è™•ç†å™¨ç‹€æ…‹"""
    stats = {
        "max_concurrent": openai_processor.max_concurrent,
        "total_requests": openai_processor.request_count,
        "current_semaphore_value": openai_processor.semaphore._value,
        "active_requests": openai_processor.max_concurrent - openai_processor.semaphore._value,
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(stats)

@app.route("/export/conversations", methods=['GET'])
def export_conversations():
    """åŒ¯å‡º Redis ä¸­çš„å°è©±ç´€éŒ„"""
    secret = request.args.get('secret')
    if secret != os.getenv('EXPORT_SECRET', 'default123'):
        return jsonify({"error": "Unauthorized"}), 401
    
    try:
        all_data = []
        cursor = '0'
        
        while True:
            cursor, keys = redis_db.scan(cursor, match="h:*", count=30)
            
            for key in keys:
                student_id = key.split(":")[1]
                messages = redis_db.lrange(key, 0, -1)
                
                student_msgs = []
                for msg_json in messages:
                    try:
                        msg = json.loads(msg_json)
                        student_msgs.append({
                            "student_id": msg["s"],
                            "role": "user" if msg["r"] == "u" else "assistant",
                            "content": msg["c"],
                            "timestamp": msg["t"]
                        })
                    except:
                        continue
                
                if student_msgs:
                    all_data.append({
                        "student_id": student_id,
                        "total_messages": len(student_msgs),
                        "messages": student_msgs[:50]
                    })
            
            if cursor == '0':
                break
        
        return jsonify({
            "export_time": datetime.now().isoformat(),
            "total_students": len(all_data),
            "data": all_data,
            "note": "From Redis (for OpenAI context)"
        }), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/test-simple", methods=['POST', 'GET'])
def test_simple():
    """æ¸¬è©¦ç«¯é»"""
    try:
        if request.method == 'GET':
            return jsonify({
                "status": "ready",
                "disk_enabled": DISK_ENABLED,
                "message": "Use POST to test"
            }), 200
        
        data = request.json or {}
        user_id = data.get('user_id', f"test_{int(time.time())}")
        message = data.get('message', 'Hello, this is a test message')
        
        print(f"ğŸ§ª Test request from {user_id}: {message[:50]}...")
        
        start_time = time.time()
        response_text = GPT_response(user_id, message)
        duration = time.time() - start_time
        
        return jsonify({
            "success": True,
            "user_id": user_id,
            "response": response_text[:500],
            "response_length": len(response_text),
            "duration_seconds": round(duration, 2),
            "disk_saved": DISK_ENABLED,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        print(f"âŒ Test error: {e}")
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500

# =============================================
# 11. å•Ÿå‹•ç¨‹å¼
# =============================================
if __name__ == "__main__":
    print(f"""
    ========================================
    ğŸš€ SICA TUTOR STARTING
    ========================================
    OpenAI Queue: {openai_processor.max_concurrent} concurrent
    Max Workers: {MAX_WORKERS}
    
    Storage:
    - Redis: For OpenAI context (fast)
    - Disk: {DISK_ENABLED} {f'at {disk_storage.mount_path}' if DISK_ENABLED else ''}
    
    Endpoints:
    - /health                : Health check
    - /disk/status          : Disk status
    - /disk/export          : Export experiment data
    - /export/conversations : Export Redis data
    - /test-simple          : Test endpoint
    ========================================
    """)
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, threaded=True)
